{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from NNetwork import NNetwork as nn\n",
    "from src.supervised_NDL.SNDL import sndl_equalEdge, sndl_predict\n",
    "from util.plotting import *\n",
    "from src.sampling.Sampling import sampling_sndl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# With Loss of Binary Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### #ntwk_list = ['Caltech36', 'UCLA26', 'true_edgelist_for_ER_5000_mean_degree_50', 'true_edgelist_for_BA_5000_m_50', 'true_edgelist_for_SW_5000_k_50_p_0.1', 'SBM1']\n",
    "ntwk_list = ['Caltech36', 'UCLA26']\n",
    "sampling_alg = 'pivot'\n",
    "save_folder = 'output/network/'\n",
    "\n",
    "graph_list = []\n",
    "for ntwk in ntwk_list:\n",
    "    path = \"data/\" + str(ntwk) + '.txt'\n",
    "    G = nn.NNetwork()\n",
    "    G.load_add_edges(path, increment_weights=False, use_genfromtxt=True)\n",
    "    graph_list.append(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Here you can try my updated sndl_equalEdge function to get a balanced sample_size_list automatically by \n",
    "just setting the parameter base_sample_size (the samplesize for the first graph).\n",
    "'''\n",
    "\n",
    "# sample_size_list = [500, 500]\n",
    "W, beta, H = sndl_equalEdge(graph_list, base_sample_size=600, k=25, xi=7, n_components=16, iter = 250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"This is W's shape: {W.shape}\")\n",
    "print(f\"This is beta's shape: {beta.shape}\")\n",
    "print(f\"This is H's shape: {H.shape}\")\n",
    "\n",
    "print(f\"\\nThis is beta {beta}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Visualize dictionaries\n",
    "display_dict_and_graph(save_path=f'output/figure/Caltech_UCLA', W=W, regression_coeff=beta.T, fig_size=[10,10], plot_graph_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = beta[0, :]\n",
    "importance = b\n",
    "idx = np.argsort(importance)\n",
    "idx = np.flip(idx)\n",
    "\n",
    "print(b[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Harvard1, MIT8, Caltech36, UCLA26, 'bn-mouse_retina_1', 'bn-mouse-kasthuri_graph_v4'\n",
    "path = \"data/\" + \"MIT8\" + '.txt'\n",
    "G3 = nn.NNetwork()\n",
    "G3.load_add_edges(path, increment_weights=False, use_genfromtxt=True)\n",
    "\n",
    "prob_ = sndl_predict(G3, W, beta, 500)\n",
    "\n",
    "prob = np.insert(prob_, 0, 1-np.sum(prob_))\n",
    "print(f\"This is the predicted probability distribution: \\n{prob}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# With Loss of Multiclass Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### #ntwk_list = ['Caltech36', 'UCLA26', 'true_edgelist_for_ER_5000_mean_degree_50', 'true_edgelist_for_BA_5000_m_50', 'true_edgelist_for_SW_5000_k_50_p_0.1', 'SBM1']\n",
    "ntwk_list = ['Caltech36', 'UCLA26', 'MIT8', 'Harvard1']\n",
    "sampling_alg = 'pivot'\n",
    "save_folder = 'output/network/'\n",
    "\n",
    "graph_list = []\n",
    "for ntwk in ntwk_list:\n",
    "    path = \"data/\" + str(ntwk) + '.txt'\n",
    "    G = nn.NNetwork()\n",
    "    G.load_add_edges(path, increment_weights=False, use_genfromtxt=True)\n",
    "    graph_list.append(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_size_list = [500, 500, 500, 500]\n",
    "W, beta, H = sndl_equalEdge(graph_list, base_sample_size=600, k=40, xi=7, n_components=16, iter = 250)\n",
    "\n",
    "'''\n",
    "Notice the confusion_mx appearing during iterations: It's a 2 by 2 matrix:\n",
    "[[TN, FP]\n",
    " [FN, TP]].\n",
    "The meaning of it is True Negative, False Positive, False Negative, True Positive respectively, which \n",
    "indicates the prediction accuracy of our parameters until the end of that iteration.\n",
    "And the accuracy report is also derived from this matrix.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"This is W's shape: {W.shape}\")\n",
    "print(f\"This is beta's shape: {beta.shape}\")\n",
    "print(f\"This is H's shape: {H.shape}\")\n",
    "\n",
    "print(f\"\\nThis is beta {beta}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Visualize dictionaries\n",
    "display_dict_and_graph(save_path=f'output/figure/Caltech_UCLA_MIT_Harvard', W=W, regression_coeff=beta.T, fig_size=[10,10], plot_graph_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Harvard1, MIT8, Caltech36, UCLA26, 'bn-mouse_retina_1', 'bn-mouse-kasthuri_graph_v4'\n",
    "path = \"data/\" + \"Harvard1\" + '.txt'\n",
    "G3 = nn.NNetwork()\n",
    "G3.load_add_edges(path, increment_weights=False, use_genfromtxt=True)\n",
    "\n",
    "prob_ = sndl_predict(G3, W, beta, 500)\n",
    "\n",
    "prob = np.insert(prob_, 0, 1-np.sum(prob_))\n",
    "print(f\"The predicted probability distribution: \\n{prob}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "REU2024",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
